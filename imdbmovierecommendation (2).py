# -*- coding: utf-8 -*-
"""imdbMovieRecommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UatSTobo2tkjjai5tTVigIN1DYCCDo0q
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

data=pd.read_csv('/content/drive/MyDrive/ratings.csv')

data.head()

data.info()

data.isnull().sum()

data.describe()

data.columns

data['userId'].nunique()

data['movieId'].nunique()

(data['userId'].value_counts().describe())

(data.groupby('movieId')['rating'].mean())

data['rating'].value_counts()

sns.histplot(data['rating'], bins=10, kde=True)

data['timestamp'] = pd.to_datetime(data['timestamp'], unit='s')

data['timestamp'].dt.year.value_counts().sort_index().plot(kind='bar')

data['timestamp'] = pd.to_datetime(data['timestamp'], unit='s')  # Timestamp'i datetime formatına çevir
data.groupby(data['timestamp'].dt.year)['rating'].mean().plot(kind='line', figsize=(10,5))
plt.title("Yıllara Göre Ortalama Rating Değişimi")
plt.xlabel("Yıl")
plt.ylabel("Ortalama Rating")
plt.grid(True)
plt.show()

top_movies = data['movieId'].value_counts().head(10)
top_movies.plot(kind='bar', figsize=(10,5), color='skyblue')
plt.title("En Çok Oylanan 10 Film")
plt.xlabel("Film ID")
plt.ylabel("Oylama Sayısı")
plt.show()

plt.figure(figsize=(10,5))
sns.histplot(data['userId'].value_counts(), bins=50, kde=True, color='orange')
plt.title("Kullanıcıların Oylama Dağılımı")
plt.xlabel("Toplam Oylama Sayısı")
plt.ylabel("Kullanıcı Sayısı")
plt.grid()
plt.show()

plt.figure(figsize=(10,5))
sns.histplot(np.log1p(data['userId'].value_counts()), bins=50, kde=True, color='orange')
plt.title("Kullanıcıların Oylama Dağılımı (Log Ölçeğinde)")
plt.xlabel("Toplam Oylama Sayısı (Log Dönüşümü)")
plt.ylabel("Kullanıcı Sayısı")
plt.grid()
plt.show()

active_users = data['userId'].value_counts()
threshold = 10  # Minimum 10 oy vermiş kullanıcılar
filtered_users = active_users[active_users >= threshold].index

filtered_data = data[data['userId'].isin(filtered_users)]
print(f"Orijinal veri seti boyutu: {data.shape}")
print(f"Filtrelenmiş veri seti boyutu: {filtered_data.shape}")

# Minimum 50 oy almış filmler
movie_counts = data['movieId'].value_counts()
movie_threshold = 50
filtered_movies = movie_counts[movie_counts >= movie_threshold].index
filtered_data = data[data['movieId'].isin(filtered_movies)]

# Minimum 50 oy vermiş kullanıcılar
user_counts = filtered_data['userId'].value_counts()
user_threshold = 50
filtered_users = user_counts[user_counts >= user_threshold].index
filtered_data = filtered_data[filtered_data['userId'].isin(filtered_users)]

print(f"Orijinal veri seti boyutu: {data.shape}")
print(f"Yeni filtrelenmiş veri seti boyutu: {filtered_data.shape}")

print(f"Filtrelenmiş kullanıcı sayısı: {filtered_data['userId'].nunique()}")
print(f"Filtrelenmiş film sayısı: {filtered_data['movieId'].nunique()}")

plt.figure(figsize=(10,5))
sns.histplot(filtered_data['userId'].value_counts(), bins=100, kde=True, color='red')
plt.title("Kullanıcıların Puanladığı Film Sayısı Dağılımı (Filtrelenmiş Veri)")
plt.xlabel("Puanladığı Film Sayısı")
plt.ylabel("Kullanıcı Sayısı")
plt.grid()
plt.show()

print(filtered_data['userId'].value_counts().describe())

plt.figure(figsize=(10,5))
sns.histplot(filtered_data['movieId'].value_counts(), bins=100, kde=True, color='blue')
plt.title("Filmlerin Oylama Sayısı Dağılımı (Filtrelenmiş Veri)")
plt.xlabel("Film Oylama Sayısı")
plt.ylabel("Film Sayısı")
plt.grid()
plt.show()

print(filtered_data['movieId'].value_counts().describe())

max_threshold = 5000
filtered_users = filtered_data['userId'].value_counts()
filtered_users = filtered_users[filtered_users <= max_threshold].index
filtered_data = filtered_data[filtered_data['userId'].isin(filtered_users)]
print(f"Yeni filtrelenmiş veri seti boyutu: {filtered_data.shape}")

min_movie_threshold = 50
filtered_movies = filtered_data['movieId'].value_counts()
filtered_movies = filtered_movies[filtered_movies >= min_movie_threshold].index
filtered_data = filtered_data[filtered_data['movieId'].isin(filtered_movies)]
print(f"Yeni filtrelenmiş veri seti boyutu: {filtered_data.shape}")

print(f"Son filtrelenmiş kullanıcı sayısı: {filtered_data['userId'].nunique()}")
print(f"Son filtrelenmiş film sayısı: {filtered_data['movieId'].nunique()}")

plt.figure(figsize=(10,5))
sns.histplot(filtered_data['userId'].value_counts(), bins=100, kde=True, color='red')
plt.title("Kullanıcıların Puanladığı Film Sayısı Dağılımı (Son Hali)")
plt.xlabel("Puanladığı Film Sayısı")
plt.ylabel("Kullanıcı Sayısı")
plt.grid()
plt.show()

plt.figure(figsize=(10,5))
sns.histplot(filtered_data['movieId'].value_counts(), bins=100, kde=True, color='blue')
plt.title("Filmlerin Oylama Sayısı Dağılımı (Son Hali)")
plt.xlabel("Film Oylama Sayısı")
plt.ylabel("Film Sayısı")
plt.grid()
plt.show()

from scipy.sparse import lil_matrix

# Kullanıcı ve film sayısını belirleme
num_users = filtered_data['userId'].nunique()
num_movies = filtered_data['movieId'].nunique()

# Sparse matrix'i bellek dostu bir formatta oluşturma
sparse_matrix = lil_matrix((num_users, num_movies))

# Kullanıcı ve Film ID'lerini kategori olarak kaydetme
user_mapping = {id: idx for idx, id in enumerate(filtered_data['userId'].unique())}
movie_mapping = {id: idx for idx, id in enumerate(filtered_data['movieId'].unique())}

# Veriyi iteratif olarak işleyeren matris
for row in filtered_data.itertuples():
    user_idx = user_mapping[row.userId]
    movie_idx = movie_mapping[row.movieId]
    sparse_matrix[user_idx, movie_idx] = row.rating

print("Bellek dostu Sparse Matrix oluşturuldu:", sparse_matrix.shape)

from sklearn.decomposition import TruncatedSVD

# SVD ile boyut indirgeme işlemi
n_components = 300  # 300 boyuta indirme (isteğe bağlı artırılabilir)
svd = TruncatedSVD(n_components=n_components, random_state=42)
svd_matrix = svd.fit_transform(sparse_matrix)

print(f"Orijinal Matris Boyutu: {sparse_matrix.shape}")
print(f"SVD ile Küçültülmüş Matris Boyutu: {svd_matrix.shape}")

from sklearn.neighbors import NearestNeighbors

knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=50, n_jobs=-1)

knn.fit(svd_matrix)

# Kullanıcı 5'in en yakın komşularını bulma işlemi
distances, indices = knn.kneighbors(svd_matrix[5].reshape(1, -1), n_neighbors=50)

print("Benzer Kullanıcıların İndeksleri:", indices)
print("Benzerlik Değerleri:", distances)

# Kullanıcı 5'in benzer kullanıcılarının indekslerini alma
similar_users = indices.flatten()[1:]  # İlk eleman (kendi ID'si) hariç tutuldu

# Benzerlik skorlarının normalize edilmesi
similarity_scores = distances.flatten()[1:]
similarity_scores = similarity_scores / similarity_scores.sum()

# Benzer kullanıcıların puanlarını alma
user_movie_ratings = filtered_data[filtered_data['userId'].isin(similar_users)]

similarity_df = pd.DataFrame({'userId': similar_users, 'similarity_score': similarity_scores})

# Puanların ve benzerlik skorlarının birleştirilmesi
user_movie_ratings = user_movie_ratings.merge(similarity_df, on='userId')

# Ağırlıklı puan hesabı
user_movie_ratings['weighted_rating'] = user_movie_ratings['rating'] * user_movie_ratings['similarity_score']

# Filmleri ağırlıklı ortalama puana göre sıralama
top_movies = user_movie_ratings.groupby('movieId')['weighted_rating'].sum().sort_values(ascending=False)

# Kullanıcı 5’in izlediği filmler
watched_movies = filtered_data[filtered_data['userId'] == 5]['movieId'].values
recommended_movies = top_movies.drop(watched_movies, errors='ignore')

# En iyi 10 film önerisi
print("Kullanıcı 5 İçin Önerilen Filmler:")
print(recommended_movies.head(10))

